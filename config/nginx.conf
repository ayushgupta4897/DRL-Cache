# NGINX Configuration with DRL Cache Module
# This configuration demonstrates how to set up DRL Cache for optimal performance

# Load DRL Cache dynamic module
load_module modules/ngx_http_drl_cache_module.so;

# Main context
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
    use epoll;
    multi_accept on;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # Logging format with cache status
    log_format cache_combined '$remote_addr - $remote_user [$time_local] '
                             '"$request" $status $body_bytes_sent '
                             '"$http_referer" "$http_user_agent" '
                             '"$upstream_cache_status" "$cache_key" '
                             '"$upstream_response_time" "$cache_ttl"';

    access_log /var/log/nginx/access.log cache_combined;
    error_log /var/log/nginx/error.log;

    # Basic optimizations
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;

    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/json
        application/javascript
        application/xml+rss
        application/atom+xml
        image/svg+xml;

    # Cache path configuration
    proxy_cache_path /var/cache/nginx/drl-cache
                     levels=1:2
                     keys_zone=drl_cache:512m
                     max_size=50g
                     inactive=12h
                     use_temp_path=off;

    # DRL Cache configuration
    drl_cache on;                                    # Enable DRL Cache
    drl_cache_k 16;                                  # Number of LRU tail candidates
    drl_cache_socket /run/drl-cache.sock;           # Sidecar socket path
    drl_cache_timeout 500us;                        # Inference timeout
    drl_cache_fallback lru;                         # Fallback to LRU on timeout
    drl_cache_min_free 512m;                        # Keep minimum free space
    drl_cache_shadow off;                           # Production mode (not shadow)

    # Feature mask for ablation studies (optional)
    # drl_cache_feature_mask age,size,hits,iat,ttl,rtt;  # All features enabled by default

    # Rate limiting
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=static:10m rate=100r/s;

    # Upstream backends
    upstream api_backend {
        server backend1.example.com:8080 max_fails=3 fail_timeout=30s;
        server backend2.example.com:8080 max_fails=3 fail_timeout=30s;
        keepalive 32;
    }

    upstream static_backend {
        server static1.example.com:80 max_fails=2 fail_timeout=10s;
        server static2.example.com:80 max_fails=2 fail_timeout=10s;
        keepalive 16;
    }

    # Main server block
    server {
        listen 80;
        listen [::]:80;
        server_name example.com www.example.com;

        # Security headers
        add_header X-Frame-Options DENY always;
        add_header X-Content-Type-Options nosniff always;
        add_header X-XSS-Protection "1; mode=block" always;
        add_header Referrer-Policy strict-origin-when-cross-origin always;

        # DRL Cache debug headers (remove in production)
        add_header X-Cache-Status $upstream_cache_status always;
        add_header X-DRL-Fallback $drl_cache_fallback always;
        add_header X-Cache-Key $cache_key always;

        # API endpoints with aggressive caching
        location /api/v1/ {
            limit_req zone=api burst=20 nodelay;

            # Cache configuration
            proxy_cache drl_cache;
            proxy_cache_key "$scheme$request_method$host$request_uri$is_args$args";
            proxy_cache_valid 200 302 10m;
            proxy_cache_valid 301 1h;
            proxy_cache_valid 404 1m;
            proxy_cache_valid any 5m;

            # Cache behavior
            proxy_cache_use_stale error timeout updating 
                                  http_500 http_502 http_503 http_504;
            proxy_cache_background_update on;
            proxy_cache_lock on;
            proxy_cache_lock_timeout 5s;
            proxy_cache_lock_age 10s;

            # Set cache variables for DRL
            set $cache_key "$scheme$request_method$host$request_uri";
            set $cache_ttl "600";  # 10 minutes

            # Proxy settings
            proxy_pass http://api_backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;

            # Timeouts
            proxy_connect_timeout 5s;
            proxy_send_timeout 30s;
            proxy_read_timeout 30s;
        }

        # Static assets with long-term caching
        location /static/ {
            limit_req zone=static burst=50 nodelay;

            # Cache configuration
            proxy_cache drl_cache;
            proxy_cache_key "$scheme$host$uri";
            proxy_cache_valid 200 24h;
            proxy_cache_valid 301 302 1h;
            proxy_cache_valid 404 10m;
            proxy_cache_valid any 1h;

            # Cache behavior
            proxy_cache_use_stale error timeout updating 
                                  http_500 http_502 http_503 http_504;
            proxy_cache_background_update on;
            proxy_ignore_headers Set-Cookie;

            # Set cache variables
            set $cache_key "$scheme$host$uri";
            set $cache_ttl "86400";  # 24 hours

            # Proxy settings
            proxy_pass http://static_backend;
            proxy_set_header Host $host;

            # Client caching headers
            expires 1d;
            add_header Cache-Control "public, immutable";
        }

        # Dynamic content with selective caching
        location / {
            # Cache configuration
            proxy_cache drl_cache;
            proxy_cache_key "$scheme$request_method$host$request_uri$is_args$args";
            proxy_cache_valid 200 5m;
            proxy_cache_valid 301 302 10m;
            proxy_cache_valid 404 1m;

            # Conditional caching
            proxy_cache_bypass $cookie_nocache $arg_nocache;
            proxy_no_cache $cookie_nocache $arg_nocache;

            # Cache behavior
            proxy_cache_use_stale error timeout updating http_500 http_502 http_503 http_504;

            # Set cache variables
            set $cache_key "$scheme$request_method$host$request_uri";
            set $cache_ttl "300";  # 5 minutes

            # Proxy settings
            proxy_pass http://api_backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # Health check endpoint (no caching)
        location /health {
            proxy_pass http://api_backend/health;
            proxy_cache off;
            access_log off;
        }

        # Cache management endpoints
        location = /cache/status {
            # Return cache statistics
            return 200 '{"cache_size": "$cache_size", "hit_ratio": "$cache_hit_ratio"}';
            add_header Content-Type application/json;
            
            # Restrict access
            allow 127.0.0.1;
            allow 10.0.0.0/8;
            allow 172.16.0.0/12;
            allow 192.168.0.0/16;
            deny all;
        }

        location = /cache/purge {
            # Cache purge endpoint
            proxy_cache_purge drl_cache "$scheme$request_method$host$uri";
            
            # Restrict access
            allow 127.0.0.1;
            allow 10.0.0.0/8;
            allow 172.16.0.0/12;
            allow 192.168.0.0/16;
            deny all;
        }
    }

    # HTTPS server block (production)
    server {
        listen 443 ssl http2;
        listen [::]:443 ssl http2;
        server_name example.com www.example.com;

        # SSL configuration
        ssl_certificate /etc/ssl/certs/example.com.pem;
        ssl_certificate_key /etc/ssl/private/example.com.key;
        ssl_session_cache shared:SSL:10m;
        ssl_session_timeout 10m;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA384;
        ssl_prefer_server_ciphers on;

        # HSTS
        add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;

        # Use same locations as HTTP server
        # ... (include all location blocks from above)
    }

    # Monitoring server (optional)
    server {
        listen 8080;
        server_name _;

        location = /nginx-status {
            stub_status on;
            access_log off;
            
            # Restrict access
            allow 127.0.0.1;
            allow 10.0.0.0/8;
            deny all;
        }

        location = /drl-cache-stats {
            # Custom endpoint for DRL cache statistics
            return 200 '{"status": "ok", "module": "drl-cache"}';
            add_header Content-Type application/json;
        }
    }
}

# Stream context for TCP/UDP load balancing (if needed)
#stream {
#    upstream backend {
#        server backend1.example.com:3306 max_fails=3 fail_timeout=30s;
#        server backend2.example.com:3306 max_fails=3 fail_timeout=30s;
#    }
#
#    server {
#        listen 3306;
#        proxy_pass backend;
#        proxy_timeout 1s;
#        proxy_responses 1;
#    }
#}
